{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAFT Dataset LlamaPack\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-raft-dataset/examples/raft_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This LlamaPack implements RAFT: Adapting Language Model to Domain Specific RAG [paper](https://arxiv.org/abs/2403.10131)\n",
    "\n",
    "Retrieval Augmented FineTuning (RAFT) is a training recipe introduced in this paper that aims to improve the performance of large language models (LLMs) in open-book, in-domain question-answering tasks. Given a question and a set of retrieved documents, RAFT trains the LLM to identify and cite verbatim the most relevant sequences from the documents that help answer the question, while ignoring irrelevant or distracting information. By explicitly training the model to distinguish between relevant and irrelevant information and to provide evidence from the relevant documents, RAFT encourages the LLM to develop better reasoning and explanation abilities, ultimately improving its ability to answer questions accurately and rationally in scenarios where additional context or knowledge is available.\n",
    "\n",
    "A key component of RAFT is how the dataset is generated for fine-tuning. Each QA pair also includes an \"oracle\" document from which the answer to the question can be deduced as well as \"distractor\" documents which are irrelevant. During training this forces the model to learn which information is relevant/irrelevant and also memorize domain knowledge.\n",
    "\n",
    "In this notebook we will create `RAFT Dataset` using `RAFTDatasetPack` LlamaPack."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (0.10.32)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.6)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.32 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.10.32)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.19)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (2024.2.0)\n",
      "Requirement already satisfied: httpx in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.24.1)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.1.18)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.23.3)\n",
      "Requirement already satisfied: pandas in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.6.4)\n",
      "Requirement already satisfied: certifi in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (2024.2.2)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (0.17.3)\n",
      "Requirement already satisfied: idna in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.3.1)\n",
      "Requirement already satisfied: click in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2024.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->llama-index-core<0.11.0,>=0.10.32->llama-index) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.32->llama-index) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.16.0)\n",
      "Collecting llama-index-packs-raft-dataset\n",
      "  Downloading llama_index_packs_raft_dataset-0.1.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: datasets<3.0.0,>=2.18.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-packs-raft-dataset) (2.18.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-packs-raft-dataset) (0.10.32)\n",
      "Requirement already satisfied: filelock in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (0.21.4)\n",
      "Requirement already satisfied: packaging in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (2.0.29)\n",
      "Requirement already satisfied: dataclasses-json in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.5.14)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.0.8)\n",
      "Requirement already satisfied: httpx in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.24.1)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.1.18)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.23.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from aiohttp->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.10 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (2.6.4)\n",
      "Requirement already satisfied: certifi in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (2024.2.2)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.17.3)\n",
      "Requirement already satisfied: idna in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.3.1)\n",
      "Requirement already satisfied: click in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (2023.12.25)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pandas->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pandas->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pandas->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (2024.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.0->llama-index-packs-raft-dataset) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pmui/anaconda3/envs/llmops/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets<3.0.0,>=2.18.0->llama-index-packs-raft-dataset) (1.16.0)\n",
      "Downloading llama_index_packs_raft_dataset-0.1.4-py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: llama-index-packs-raft-dataset\n",
      "Successfully installed llama-index-packs-raft-dataset-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-packs-raft-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<YOUR OPENAI API KEY>\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-26 17:01:32--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 100.64.4.48\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|100.64.4.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘./paul_graham_essay.txt’\n",
      "\n",
      "./paul_graham_essay 100%[===================>]  73.28K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2024-04-26 17:01:32 (1.13 MB/s) - ‘./paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\" -O './paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.packs.raft_dataset import RAFTDatasetPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_dataset = RAFTDatasetPack(\"./paul_graham_essay.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Number of chunks created: 39\n",
      "INFO:root:Processing chunk: 0\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 1\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 2\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 3\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 4\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 5\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 6\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 7\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 8\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 9\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 10\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 11\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 12\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 13\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 14\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 15\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 16\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 17\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 18\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 19\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 20\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 21\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 22\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 23\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 24\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 25\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 26\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 27\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 28\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 29\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 30\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 31\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 32\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 33\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 34\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 35\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 36\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 37\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing chunk: 38\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Beware of the costs invloved. This will use GPT-4 for dataset creation.\n",
    "# It will also take long time based on the file size.\n",
    "dataset = raft_dataset.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above dataset is HuggingFace Dataset format. You can then save it into `.arrow` or `.jsonl` format and use it for further finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f33d3086ac54fde9a41f8241c8f3565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/191 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd9a9fa851948ed972127b0e3b86aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2899192"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = \"./output/paul_graham_dataset\"\n",
    "# Save as .arrow format\n",
    "dataset.save_to_disk(output_path)\n",
    "\n",
    "# Save as .jsonl format\n",
    "dataset.to_json(output_path + \".jsonl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can refer to the original implementation [here](https://github.com/ShishirPatil/gorilla/tree/main/raft)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
